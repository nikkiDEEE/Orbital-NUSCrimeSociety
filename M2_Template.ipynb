{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikkiDEEE/Orbital-NUSCrimeSociety/blob/main/M2_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkAYBhuYdolz"
      },
      "source": [
        "# ðŸš¨ **NUS Crime Society** ðŸš¨\n",
        "\n",
        "# VIOLENT BEHAVIOUR AND WEAPON DETECTOR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://techzizou.com/train-a-custom-yolov4-tiny-object-detector-using-google-colab-tutorial-for-beginners/)"
      ],
      "metadata": {
        "id": "4rl7nTxppcDV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oMYIMKkad8d"
      },
      "source": [
        "#**Setup**\n",
        "\n",
        "* Click on **File** in the menu bar and click on **Save a copy in drive**. This will open a 'Copy of' this Colab notebook on the browser and save it in the drive.\n",
        "\n",
        "* Next, after opening the copy of my notebook and connected to the Colab VM, click on **Runtime** in the menu bar and click on **Change runtime type**. Select **GPU** and click on save."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8X8ScyqhHP0"
      },
      "source": [
        "# **12 Steps for SUCCESS**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2xRNY0gJVLa"
      },
      "source": [
        "# **1) Clone `darknet` git repository onto the Colab VM** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kShUEMv4JVLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f23609d-280f-4a74-e4ad-0639e0820627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 15424, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 15424 (delta 0), reused 1 (delta 0), pack-reused 15423\u001b[K\n",
            "Receiving objects: 100% (15424/15424), 14.03 MiB | 8.74 MiB/s, done.\n",
            "Resolving deltas: 100% (10365/10365), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXtlWSf2JVLe"
      },
      "source": [
        "# **2) Create *`yolov4-tiny`* and *`training`* folders in your drive**\n",
        "\n",
        " Create a folder named ***yolov4-tiny*** in your drive. \n",
        " \n",
        " Next, create another folder named ***training*** inside the ***yolov4-tiny*** to save the trained weights. (This path is mentioned in the obj.data file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc5fZPrdJVLf"
      },
      "source": [
        "# **3) Create & upload these files**\n",
        "\n",
        "What we need for training custom yolo detector\n",
        "\n",
        "a.   BBox Labeled Violence Dataset\n",
        "\n",
        "b.   Custom cfg (config) file (hyper-parameters)\n",
        "\n",
        "c.   obj.data (training .jpg + .txt) and obj.names (classes) files\n",
        "\n",
        "d.   process.py file (to create train.txt and test.txt files for training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-rFNDHbPB2t"
      },
      "source": [
        "## **3(a) Upload the Labeled custom dataset *`obj.zip`* file to the *`yolov4-tiny`* folder on the drive**\n",
        "\n",
        "Create the zip file **obj.zip** from the **obj** folder containing both the input image \".jpg\" files and their corresponding Darknet YOLO format labeled \".txt\" files.\n",
        "\n",
        "Upload the zip file to the ***yolov4-tiny*** folder on your drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ylNPngPB2u"
      },
      "source": [
        "## **3(b) Create your custom *`config`* file and upload it to your drive**\n",
        "\n",
        "Download the **yolov4-tiny-custom.cfg** file from ***darknet/cfg*** directory, make changes to it, and upload it to the ***yolov4-tiny*** folder on your drive .\n",
        "\n",
        "You can also download the custom config files from the official [AlexeyAB Github](https://www.github.com/AlexeyAB/darknet)\n",
        "\n",
        "**You need to make the following changes in your custom config file:**\n",
        "\n",
        "\n",
        "\n",
        "*   change line batch to **batch=64**\n",
        "*   change line subdivisions to **subdivisions=16**\n",
        "*   change line max_batches to (classes x 2000 but not less than number of training images, but not less than number of training images and not less than 6000), f.e. **max_batches=10000** if you train for 5 classes\n",
        "*    change line steps to 80% and 90% of max_batches, f.e. **steps=8000,9000**\n",
        "*    set network size **width=416 height=416** or any value multiple of 32\n",
        "*    change line **classes=5** to your number of objects in each of 2 [yolo]-layers\n",
        "*    change [filters=255] to filters=(classes+5)x3 in the 2 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
        "     So if classes=1 then it should be filters=18. If classes=5 then write **filters=30**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyO4xO43PB2v"
      },
      "source": [
        "## **3(c) Create your *`obj.data`* and *`obj.names`* files and upload them to your drive**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzl9NXKBPB2v"
      },
      "source": [
        "### **obj.data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iytWxrEPB2w"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "classes = 5\n",
        "train  = data/train.txt\n",
        "valid  = data/test.txt\n",
        "names = data/obj.names\n",
        "backup = /mydrive/yolov4-tiny/training\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoevtQQYPB24"
      },
      "source": [
        "## **3(d) Upload the *`process.py`* script file to the *`yolov4-tiny`* folder on your drive**\n",
        "\n",
        "**To divide all image files into 2 parts. 90% for train and 10% for test.**\n",
        "\n",
        "This *process.py* script creates the files *train.txt* & *test.txt* where the *train.txt* file has paths to 90% of the images and *test.txt* has paths to 10% of the images.\n",
        "\n",
        "You can download the ***`process.py`*** script from my [GitHub](https://github.com/techzizou/yolov4-tiny-custom_Training).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sMAuHQiPB2-"
      },
      "source": [
        "# **4) Mount drive and link the folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oALy-2wQPB2-"
      },
      "outputs": [],
      "source": [
        "#mount drive\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "# list contents in yolov4-tiny folder in your drive\n",
        "!ls /mydrive/yolov4-tiny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJoL2xPqJ_5I"
      },
      "source": [
        "# **5) Make changes in the `makefile` to enable OPENCV and GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_puvebJJ_5J"
      },
      "outputs": [],
      "source": [
        "# change makefile to have GPU and OPENCV enabled\n",
        "# also set CUDNN, CUDNN_HALF and LIBSO to 1\n",
        "\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE_sGR2bJ_5J"
      },
      "source": [
        "# **6) Run `make` command to build darknet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWQWmvq_J_5J"
      },
      "outputs": [],
      "source": [
        "# build darknet \n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHazNXGSJ_5K"
      },
      "source": [
        "# **7) Copy files from the drive to the darknet directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aK5ur5KsXOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da937976-ebdf-41ca-cfdf-291edf2088eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet/data\n",
            "/content/darknet\n"
          ]
        }
      ],
      "source": [
        "# Clean the data and cfg folders first except the labels folder in data which is required\n",
        "\n",
        "%cd data/\n",
        "!find -maxdepth 1 -type f -exec rm -rf {} \\;\n",
        "%cd ..\n",
        "\n",
        "%rm -rf cfg/\n",
        "%mkdir cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDMYvZFJJ_5K"
      },
      "outputs": [],
      "source": [
        "#copy the datasets zip file to the root darknet folder\n",
        "!cp /mydrive/yolov4-tiny/obj.zip ../\n",
        "\n",
        "# unzip the datasets and their contents so that they are now in /darknet/data/ folder\n",
        "!unzip ../obj.zip -d data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_8ijd3DJ_5L"
      },
      "outputs": [],
      "source": [
        "#copy the custom cfg file from the drive to the darknet/cfg folder\n",
        "!cp /mydrive/yolov4-tiny/yolov4-tiny-custom.cfg ./cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddfOsTymJ_5L"
      },
      "outputs": [],
      "source": [
        "# copy the obj.names and obj.data files so that they are now in /darknet/data/ folder\n",
        "!cp /mydrive/yolov4-tiny/obj.names ./data\n",
        "!cp /mydrive/yolov4-tiny/obj.data  ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDRwwKnsJ_5L"
      },
      "outputs": [],
      "source": [
        "#copy the process.py file from the drive to the darknet directory\n",
        "!cp /mydrive/yolov4-tiny/process.py ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgOJwRmkPB3E"
      },
      "source": [
        "# **8) Run the *`process.py`* python script to create the *`train.txt`* & *`test.txt`* files inside the *data* folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACGu8EZIPB3E"
      },
      "outputs": [],
      "source": [
        "# run process.py ( this creates the train.txt and test.txt files in our darknet/data folder )\n",
        "!python process.py\n",
        "\n",
        "# list the contents of data folder to check if the train.txt and test.txt files have been created \n",
        "!ls data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dSOghlbPB3E"
      },
      "source": [
        "# **9) Download the pre-trained *`yolov4-tiny`* weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLZ0EST5PB3E"
      },
      "outputs": [],
      "source": [
        "# Download the yolov4-tiny pre-trained weights file\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZpOV-xYPB3F"
      },
      "source": [
        "# **10) Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4roT81BPB3F"
      },
      "source": [
        "## **Train your custom detector** \n",
        "\n",
        "For best results, you should stop the training when the average loss is less than 0.05 if possible or at least constantly below 0.3, else train the model until the average loss does not show any significant change for a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raDMjwwhPB3F"
      },
      "outputs": [],
      "source": [
        "# train your custom detector! (uncomment %%capture below if you run into memory issues or your Colab is crashing)\n",
        "# %%capture\n",
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov4-tiny-custom.cfg yolov4-tiny.conv.29 -dont_show -map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "DzhFMg08PB3G",
        "outputId": "a90152d6-7d83-4d2b-c8dd-eb212f1f31c0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-90e9831ca4f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This stops 'Run all' at this cell by causing an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# This stops 'Run all' at this cell by causing an error\n",
        "assert False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-YOus-FPB3G"
      },
      "source": [
        "## **To restart the training (In case training does not finish and you get disconnected)**\n",
        "\n",
        "If you get disconnected or lose your session, you can restart training from where you left off without having to start from scratch again. The weights are saved every 100 iterations as ***yolov4-tiny-custom_last.weights*** in the ***yolov4-tiny/training*** folder on your drive. (The path we gave as backup in \"obj.data\" file). \n",
        "\n",
        "**Run steps 1,4,5,6,7,8 to restart training from the last saved checkpoint and run the following command:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar7jKR-Jmq4Y"
      },
      "outputs": [],
      "source": [
        "#to restart training your custom detector where you left off(using the weights that were saved last)\n",
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov4-tiny-custom.cfg /mydrive/yolov4-tiny/training/yolov4-tiny-custom_10000.weights -dont_show -map"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This stops 'Run all' at this cell by causing an error\n",
        "assert False"
      ],
      "metadata": {
        "id": "wjUA6OoL2Fz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ZR1Cv5iSiH"
      },
      "source": [
        "# **11) Check performance** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmjcPvWyarZ6"
      },
      "outputs": [],
      "source": [
        "# define helper function imShow\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  #plt.show('')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_s3oI7Rnic3"
      },
      "outputs": [],
      "source": [
        "#only works if the training does not get interrupted \n",
        "imShow('chart.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa9j0M4-au8q"
      },
      "source": [
        "**Check mAP (Mean Average Precision)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhlceb1YiEwu"
      },
      "outputs": [],
      "source": [
        "#You can check the mAP for all the saved weights to see which gives the best results ( xxxx here is the saved weight number like 4000, 5000 or 6000 snd so on )\n",
        "\n",
        "!./darknet detector map data/obj.data cfg/yolov4-tiny-custom.cfg /mydrive/yolov4-tiny/training/yolov4-tiny-custom_best.weights -points 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkVfpYU3vK-W"
      },
      "source": [
        "# **12) Test your custom Object Detector**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRoFfkBFT7Hm"
      },
      "source": [
        "## **Make changes to your custom config file**\n",
        "*   change line batch to batch=1\n",
        "*   change line subdivisions to subdivisions=1\n",
        "\n",
        "You can do it either manually or by simply running the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UddToJtjkSaO",
        "outputId": "d4ae77aa-5b40-4eb9-b1c3-3d4f90d01b80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/darknet/cfg\n",
            "/content/darknet\n"
          ]
        }
      ],
      "source": [
        "#set your custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-tiny-custom.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-tiny-custom.cfg\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGzCTHKliv16"
      },
      "source": [
        "## **Run detector on an image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUBkR6JgU4tX"
      },
      "outputs": [],
      "source": [
        "# run your custom detector with this command (upload an image to your google drive to test, the thresh flag sets the minimum accuracy required for object detection)\n",
        "\n",
        "!./darknet detector test data/obj.data cfg/yolov4-tiny-custom.cfg /mydrive/yolov4-tiny/training/yolov4-tiny-custom_best.weights /mydrive/mask_test_images/image1.jpg -thresh 0.3\n",
        "imShow('predictions.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io0OaKMCV4DX"
      },
      "source": [
        "## **Run detector on a webcam image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SXjyRtEQ20u"
      },
      "outputs": [],
      "source": [
        "#Run detector on images captured by webcam for your custom YOLOv4-tiny trained model\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "\n",
        "!./darknet detector test data/obj.data cfg/yolov4-tiny-custom.cfg /mydrive/yolov4-tiny/training/yolov4-tiny-custom_best.weights photo.jpg -thresh 0.5\n",
        "imShow('predictions.jpg')   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUgEa-HVixkj"
      },
      "source": [
        "## **Run detector on a video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBzzSarwJh89"
      },
      "outputs": [],
      "source": [
        "# run your custom detector on a video with this command (upload a video to your google drive to test, the thresh flag sets the minimum accuracy required for object detection).This saves the output video with the detections in your output path\n",
        "\n",
        "!./darknet detector demo data/obj.data cfg/yolov4-tiny-custom.cfg /mydrive/yolov4-tiny/training/yolov4-tiny-custom_best.weights -dont_show /mydrive/mask_test_videos/test3.mp4 -i 0 -out_filename /mydrive/mask_test_videos/result.avi "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "___wZk_UJo08"
      },
      "source": [
        "## **Run detector on a live webcam**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiSatc-T2Sbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "d4a41a29-f5fb-4a80-f1b0-079047624dd1"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0b2c1f7a7fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0b2c1f7a7fd3>\u001b[0m in \u001b[0;36mvideo_frame\u001b[0;34m(label, bbox)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stream_frame(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Cannot read properties of undefined (reading 'style')"
          ]
        }
      ],
      "source": [
        "# Code from theAIGuysCode Github (https://github.com/theAIGuysCode/YOLOv4-Cloud-Tutorial/blob/master/yolov4_webcam.ipynb)\n",
        "#adjusted for my custom YOLOv4-tiny trained weights, config and obj.data files\n",
        "\n",
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# import darknet functions to perform object detections\n",
        "from darknet import *\n",
        "# load in our YOLOv4 architecture network\n",
        "network, class_names, class_colors = load_network(\"cfg/yolov4-tiny-custom.cfg\", \"data/obj.data\", \"/mydrive/yolov4-tiny/training/yolov4-tiny-custom_best.weights\")\n",
        "width = network_width(network)\n",
        "height = network_height(network)\n",
        "\n",
        "# darknet helper function to run detection on image\n",
        "def darknet_helper(img, width, height):\n",
        "  darknet_image = make_image(width, height, 3)\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img_resized = cv2.resize(img_rgb, (width, height),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # get image ratios to convert bounding boxes to proper size\n",
        "  img_height, img_width, _ = img.shape\n",
        "  width_ratio = img_width/width\n",
        "  height_ratio = img_height/height\n",
        "\n",
        "  # run model on darknet style image to get detections\n",
        "  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "  detections = detect_image(network, class_names, darknet_image)\n",
        "  free_image(darknet_image)\n",
        "  return detections, width_ratio, height_ratio\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes  \n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # call our darknet helper on video frame\n",
        "    detections, width_ratio, height_ratio = darknet_helper(frame, width, height)\n",
        "\n",
        "    # loop through detections and draw them on transparent overlay image\n",
        "    for label, confidence, bbox in detections:\n",
        "      left, top, right, bottom = bbox2points(bbox)\n",
        "      left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n",
        "      bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), class_colors[label], 2)\n",
        "      bbox_array = cv2.putText(bbox_array, \"{} [{:.2f}]\".format(label, float(confidence)),\n",
        "                        (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        class_colors[label], 2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afZcMjuiLEUi"
      },
      "source": [
        "# ðŸš¨ **NUS Crime Society** ðŸš¨"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "M2_Template.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}